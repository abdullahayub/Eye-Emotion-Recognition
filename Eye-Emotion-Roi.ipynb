{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import mediapipe as mp\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from tensorflow.keras import Model\n",
    "import time\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For webcam input:\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(max_num_faces=3,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "def get_features(pr_model, data,width=350):\n",
    "    cnn_model = pr_model(include_top=False, input_shape=(width, width, 3), weights='imagenet')\n",
    "    inputs = Input((width, width, 3))\n",
    "    x = inputs\n",
    "    x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "    x = cnn_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs, x)\n",
    "    features = cnn_model.predict(data, batch_size=5, verbose=1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"eye_roi\"\n",
    "encoder = LabelEncoder()\n",
    "encoder.classes_ = np.load(path+'/classes.npy')\n",
    "model = load_model(path+\"/Functional_model.h5\")\n",
    "\n",
    "\n",
    "# used to record the time when we processed last frame\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "# used to record the time at which we processed current frame\n",
    "new_frame_time = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    prev_frame_time = 0\n",
    "    image2 = image.copy()\n",
    "    image2 = cv2.flip(image2, 1)\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display, and convert\n",
    "    # the BGR image to RGB.\n",
    "    image =cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # Draw landmark annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    h,w,d = image.shape\n",
    "    l2 =[] \n",
    "    if results.multi_face_landmarks:\n",
    "\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            dict1 = {}\n",
    "            a =mp_drawing.draw_landmarks(\n",
    "                image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=drawing_spec,\n",
    "                connection_drawing_spec=drawing_spec)\n",
    "            for idx,lm, in enumerate(face_landmarks.landmark):\n",
    "                if idx in (54,123,284,352):\n",
    "                    cx,cy = int(lm.x*w),int(lm.y*h)\n",
    "                    if idx in  (154,284):#above Eyebrow\n",
    "                        cy=cy-10\n",
    "                    dict1[str(idx)] = (cx,cy)\n",
    "                    cv2.circle(image,(cx,cy),5,(255,0,255),cv2.FILLED)     \n",
    "                    # image = cv2.putText(image, str(idx), (cx,cy-2), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    # 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "            l2.append(dict1)\n",
    "\n",
    "        for dict1 in l2:\n",
    "            Eye_roi = image2[dict1[\"54\"][1]:dict1[\"123\"][1],dict1[\"54\"][0]:dict1[\"352\"][0]]\n",
    "\n",
    "            Eye_roi  = cv2.resize(Eye_roi,(350,350))\n",
    "\n",
    "            Eye_roi_reshape = Eye_roi.copy()\n",
    "            Eye_roi_reshape = Eye_roi.reshape(1,350,350,3)\n",
    "            print(Eye_roi_reshape.shape,\"SHape********\")\n",
    "\n",
    "            inception_features = get_features(InceptionV3,Eye_roi_reshape)\n",
    "            xception_features = get_features(Xception,Eye_roi_reshape)\n",
    "            features_test = np.concatenate([inception_features, xception_features],axis=1)\n",
    "\n",
    "\n",
    "            pred = model.predict(features_test)\n",
    "            y_decode = np.argmax(pred,axis=1)\n",
    "            y_decode1 = encoder.inverse_transform(y_decode)\n",
    "            print(y_decode1,\"Decode Emotion================\")\n",
    "            cv2.putText(image2, str(y_decode1[0]).upper(), (dict1[\"54\"][0],dict1[\"54\"][1]), font, 1, (50, 50, 250), 2, cv2.LINE_AA)\n",
    "            cv2.rectangle(image2,(dict1[\"54\"][0],dict1[\"54\"][1]),(dict1[\"284\"][0],dict1[\"123\"][1]),(0,255,0),2)\n",
    "        #time when we finish processing for this frame\n",
    "\n",
    "        if camera:\n",
    "            new_frame_time = time.time()\n",
    "            fps = 1/(new_frame_time-prev_frame_time)\n",
    "            prev_frame_time = new_frame_time\n",
    "            cv2.putText(image2, \"FPS:\"+str(round(fps,2)), (7, 30), font, 1.2, (100, 255, 0), 2, cv2.LINE_AA)\n",
    "        return image2,Eye_roi\n",
    "    else:\n",
    "        return image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path=\"img\"\n",
    "camera = True\n",
    "#cap = cv2.VideoCapture(0)#0 for webcam\n",
    "\n",
    "\n",
    "if camera:\n",
    "    while True:\t\n",
    "        #success, image = cap.read()qq\n",
    "        #success, \n",
    "        image = cv2.imread('img1.jpg')\n",
    "#         if not success:\n",
    "#             print(\"Ignoring empty camera frame.\")\n",
    "#             # If loading a video, use 'break' instead of 'continue'.\n",
    "#             continue\n",
    "       \n",
    "        if image.shape:\n",
    "            image,roi = process_image(image)\t\n",
    "            #cv2.imshow('Eye Roi',roi)\n",
    "            #cv2.imshow(\"Image-ouput\",image)\n",
    "            cv2.imwrite(f\"{path}/output.jpg\",image)\n",
    "            cv2.imwrite(f\"{path}/roi.jpg\",roi)\n",
    "        else:\n",
    "            break\n",
    "#         except: \n",
    "#             print(\"image not load\")\n",
    "#             continueq\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "else:\n",
    "    image = cv2.imread(f\"img1.jpg\")\n",
    "    #cv2.imshow('Original Image',image)\n",
    "    if image.shape:\n",
    "        image,roi = process_image(image)\n",
    "        cv2.imwrite(f\"{path}/output.jpg\",image)\n",
    "        cv2.imwrite(f\"{path}/roi.jpg\",roi)\n",
    "\n",
    "\n",
    "face_mesh.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
